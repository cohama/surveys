3D Gaussian Splatting as
Markov Chain Monte Carlo
マルコフ連鎖モンテカルロ法による３Dガウススプラッティング

===


Author:Shakiba Kheradmand1, Daniel Rebain1, Gopal Sharma1,
Weiwei Sun1, Yang-Che Tseng1, Hossam Isack2, Abhishek Kar2,
Andrea Tagliasacchi3, 4, 5, Kwang Moo Yi1
Organization:[1University of British Columbia, 2Google Research,
3Google DeepMind, 4Simon Fraser University, 5University of Toronto]()


URL：https://ubc-vision.github.io/3dgs-mcmc/paper.pdf
GitHub：https://ubc-vision.github.io/3dgs-mcmc/


(まとめ：Hisashi Takagi）

---

## どんなもの？

+ 本論文では、モンテカルロ法 (MCMC) を用いて、3D形状学習手法を提案します。このアプローチは、複雑な形状や多様なオブジェクトの3D再構築において、効率的で頑強なソリューションを提供します
+ 既存の最先端技術と比較して、複雑な3D形状の再構築において有効性を示しました
+ 特に、少ないデータセットでの高精度な3D形状推定が可能であることが示されました



## 背景

その前に3Dガウス・スプラッティングについて軽く説明
※3D Gaussian Splattingについて調べてみた
https://qiita.com/harutine/items/e5bed074067dad429285?utm_source=stock_summary_mail&utm_medium=email&utm_term=jyuan0128&utm_content=3D%20Gaussian%20Splatting%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6%E8%AA%BF%E3%81%B9%E3%81%A6%E3%81%BF%E3%81%9F&utm_campaign=stock_summary_mail_2024-06-29#%E8%AB%96%E6%96%87


NeRFに関する研究の中で、我々の研究に最も関連するのは[15]であり、SGLD(Stochastic Gradient Langevin Dynamics)[3]を採用し、学習に最も有望なサンプルを特定し、より速い学習収束を可能にしている。我々は、SGLDに基づく同じマルコフ連鎖モンテカルロ（MCMC）パラダイムに立脚しているが、アプリケーションの文脈は全く異なる。彼らの研究では、SGLDは「ソフトマイニング」の一種を実行するために使用され、NeRFの学習を加速させる。我々の場合、代わりに3DGSを3Dシーンを表現する基礎となる分布からのサンプルとして再考している。

ガウス・スプラッティング。
3D Gaussian Splatting（3DGS）[14]は、ボリュームレンダリングの代わりに微分可能なラスタライゼーションに依存する、NeRFに代わる最近の手法である。一言で言えば、レイに沿った点をクエリする代わりにガウシアンを保存し、それを各ビューにラスタライズして画像を形成する。このラスタライズ操作は非常に効率的で、ピクセルをレンダリングするために光線に沿って何百ものポイントを照会する代わりに、与えられたピクセルに関連する（少数の）ガウシアンをラスタライズするだけでよい。したがって、ガウス・スプラッティングにより、最新のGPUで1080pの画像を毎秒130フレームでレンダリングできるようになり、研究コミュニティが活性化した。

この研究では、3Dガウシアンの集合を、基本的な確率分布から引き出されたランダムなサンプルとして考え直す。つまり、マルコフ連鎖モンテカルロ（MCMC）サンプルである。この考え方の下で、3Dガウシアン更新が、次のように変換できることを示す。
そして、スプラッティングを単にMCMCサンプルの決定論的状態遷移として書き直す。
これらのヒューリスティックをフレームワークから取り除く。
ガウシアンの効率的な利用を促すために、正則化を導入する。
様々な標準的な評価シーンにおいて
我々の手法は、レンダリング品質の向上、ガウシアンの数を容易に制御でき、初期化に対して頑健であることを示す。


## どうやって有効だと検証した？

+ 使用データセット: NeRF Synthetic、Tank & Temples、Deep Blending、MipNeRF 360、OMMOの各データセットを使用。
+ データ処理: 一部のデータセットはダウンサンプリングして使用。
+ 評価指標: PSNR、SSIM、LPIPSを用い、全ての実験を3回行って平均化。
+ 比較対象: 従来の3DGS手法や最先端のベースライン手法と比較。

データセットの詳細

+ NeRF Synthetic データセット: 全シーンを使用。
+ Tank & Temples データセット: [14]で使用された2つのシーンを採用。
+ Deep Blending データセット: 全シーンを使用。
+ MipNeRF 360 データセット: 公開されている全シーンを使用。
+ OMMO データセット: [9]で使用された全シーンを採用、大規模で遠距離の物体を含むシーンに対応。


MipNeRF 360 データセットでは、[14]の結果と互換性を持たせるために、屋内シーンは2倍、屋外シーンは4倍にダウンサンプリングしました。OMMO データセットのシーン #01 では、画像サイズを1000×750ピクセルに保つために、4倍にダウンサンプリングしています。他のシーンについては、元の画像解像度を使用しています。

評価指標

各手法の評価には、以下の3つの標準的な指標を使用しました：

+ ピーク信号対雑音比 (PSNR)
+ 構造類似性指標 (SSIM)
+ 学習型知覚画像パッチ類似度 (LPIPS)

※ピーク信号対雑音比 (PSNR)
PSNRは、デジタル画像の品質を評価するための尺度で、再構成された画像の品質をオリジナル画像と比較して評価します。

※SSIMは、画像の構造的情報を保持する能力を評価するために使用されます。これは、人間の視覚特性を模倣するように設計されており、以下の要素を考慮します：
輝度 (luminance)
コントラスト (contrast)
構造 (structure)

※学習型知覚画像パッチ類似度 (LPIPS)
LPIPSは、ニューラルネットワークを用いて画像の知覚的な違いを評価する指標です。これは、画像のパッチを用いて、人間の視覚に基づいた知覚的な類似度を計算します。

全ての実験は3回行い、ランダム性を考慮して結果を平均化しています。

ベースライン

我々は、従来の3Dガウススプラッティング（3DGS）[14]と比較し、ランダムなポイントクラウドと構造から動き（SfM）に基づく初期化戦略を用いました。実験には公式コードを使用し、3DGS [14]のオリジナルの数値も報告していますが、[4]によるLPIPSスコアの修正を反映しています。さらに、各データセットに対する最先端のベースライン手法も含めています。

---

## 技術や手法の肝は？


+ 新しい解釈: 3D Gaussian Splatting（3DGS）のトレーニングプロセスを、ガウス分布の配置と最適化のサンプリングプロセスとして解釈します。
+ 分布の定義: ガウス集合がトレーニング画像を忠実に再構築する確率が高くなるような分布を定義し、これによりMCMCを利用してサンプルを引き出します。
+ SGLDの利用: SGLD法を使用し、ガウス分布のパラメータを確率的に更新することで、従来のSGDと類似した形式での更新を行います。
+ 数学的整合性: ガウススプラッティングの分割や剪定の操作を離散的に行っても、勾配ベースの最適化の連続性の前提を破らずに済みます。
+ 等式の類似性: 標準的な3D Gaussian Splattingの最適化は、レンダリングの質に結びついた尤度分布からのサンプリングとして理解することができ、SGLDの更新ルールに類似しています。

本セクションでは、3D Gaussian Splatting（3DGS）の新しい解釈として、ガウス配置と最適化のトレーニングプロセスをサンプリングプロセスとして捉える方法を提案します。従来の方法とは異なり、単に損失関数を定義し、その局所最小値に向かってステップを取るのではなく、ガウス集合がトレーニング画像を忠実に再構築する確率が高くなるような分布を定義します。この選択により、MCMCフレームワークの力を借りて、この分布からサンプルを数学的に扱いやすい方法で引き出すことが可能になります。これは、パラメータ空間で離散的な変更を行う際にも有効です。

したがって、ガウススプラッティングの元々の分割や剪定のヒューリスティックに類似した離散的な操作を設計することができ、通常の勾配ベースの最適化の前提である連続性を破ることなく実現できます。

手法の概要

この目的を達成するために、まず Stochastic Gradient Langevin Dynamics (SGLD) 法を使用します。SGLDは、MCMCフレームワークの一種で、最近では新しいビュー合成の応用にも使用されています。この選択は便利であり、SGLDは一般に使用されるStochastic Gradient Descent (SGD) の更新ルールに似ていますが、追加の確率的なノイズがあります。

具体的には、3DGSにおける単一のガウス 𝑔 の更新を考え、分割/結合のヒューリスティックを一時的に無視すると、以下のようになります：

𝑔←𝑔−𝜆𝑙𝑟⋅∇𝑔𝐸𝐼∼𝐼[𝐿𝑡𝑜𝑡𝑎𝑙(𝑔;𝐼)]g←g−λ lr ⋅∇ ​ E I∼I [L total​ (g;I)] (4)

ここで、
𝜆𝑙𝑟 は学習率であり、I はトレーニング画像セット I からサンプリングされた画像です。

これを通常のSGLDの更新と比較すると：

𝑔←𝑔+𝑎⋅∇𝑔log⁡𝑃(𝑔)+𝑏⋅𝜖 (5)

ここで、
𝑃はサンプリングしたい分布に対するデータ依存の確率密度関数であり、
𝜖は探索のためのノイズ分布です。ハイパーパラメータ 
a と b は、収束速度と探索のバランスを制御します。

等式の類似性
式 (4) と (5) の間には驚くほどの類似性があります。言い換えれば、損失を基礎となる分布の負の対数尤度として考えることで、以下のようになります：

G =P ∝exp(−Ltotal), (6)

b=0 のとき、式は同一となります。したがって、標準的なガウススプラッティングの最適化は、レンダリングの質に結びついた尤度分布からサンプリングされたガウスを持つこととして理解することができます。

---

## 議論はある？


+ 比較画像を見ると、遠方の景色など鮮明に判別できる＝解像度が高い？
+ 予算の制約？　サンプリングの量と質の確保
+ 初期値に依存しなくなるけど従来の手法との相性が良くない（かえって悪化）

補足：
Stochastic Gradient Langevin Dynamics (SGLD) 法と Stochastic Gradient Descent (SGD) 法主な違い

雑音の有無:

+ SGDでは、パラメータ更新にランダムな雑音を加えないため、収束が速い一方で、局所最小値にとどまりやすい。
+ SGLDでは、更新にガウス雑音を加えることで、パラメータが事後分布に従うようになり、ベイズ推定に有用なサンプルを生成できる。

適用領域:

+ SGDは、主にディープラーニングや一般的な最適化問題で使用される。
+ SGLDは、ベイズ統計や不確実性の評価が重要な場合に使用される。

理論的背景:

+ SGDは、単純な勾配降下法に基づいており、凸最適化問題に対して理論的保証があります。
+ SGLDは、Langevin DynamicsとMCMCに基づいており、確率的最適化とベイズ推定の理論的背景を持っています。

注：
Langevin Dynamicsは、ニュートンの運動方程式に摩擦とランダムな力を加えることで、物理システムの動力学をモデル化する手法です。分子動力学や統計物理学、機械学習など幅広い分野で応用されており、系の熱平衡や粒子の熱揺動（ブラウン運動）を正確に表現するのに役立ちます。

Langevin Dynamicsの利点
+ 熱効果のモデル化:
　熱揺動と摩擦を同時に考慮することで、実際の物理系に近いシミュレーションが可能です。
+ エルゴード性:
長時間のシミュレーションにより、系が全ての可能な状態を探索することを保証します。これは、系の平衡分布を正確にサンプリングするために重要です。

---

## 先行研究と比べて何がすごい？

+ 本研究の戦略に基づいた実装によりオリジナルの手法を超えた高精細な結果が得られた
+ 初期値に関わらないロバスト性を実現
+ MipNeRF3360[2]データセットでNeRFバックボーンを凌駕する3DGS実装につながることを初めて示す


---

## 次に読むべき論文は？

とりあえず、実装を色々試し中
+ ステレオグラム？　視差のある画像を２つ生成する手法
+ ４D ガウシアンもあるらしい
+ UnityやUEへの実装も進行中　メタバースへ持ってこれる？

  
+ [Awesome 3D Gaussian Splatting Resources](https://github.com/MrNeRF/awesome-3D-gaussian-splatting)
 


